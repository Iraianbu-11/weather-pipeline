{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache Spark Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, lit, round\n",
    "spark = SparkSession.builder.appName(\"Weather Analytics\").enableHiveSupport().master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+----+----+--------------------+----+--------------------+-------+-------+-------+-------+-------------+---------+\n",
      "|Precipitation|  FullDate|Month|Week|Year|                City|Code|            Location|  State|AvgTemp|MaxTemp|MinTemp|WindDirection|WindSpeed|\n",
      "+-------------+----------+-----+----+----+--------------------+----+--------------------+-------+-------+-------+-------+-------------+---------+\n",
      "|          0.0|2016-01-03|    1|   3|2016|          Birmingham| BHM|      Birmingham, AL|Alabama|     39|     46|     32|           33|     4.33|\n",
      "|          0.0|2016-01-03|    1|   3|2016|          Huntsville| HSV|      Huntsville, AL|Alabama|     39|     47|     31|           32|     3.86|\n",
      "|         0.16|2016-01-03|    1|   3|2016|              Mobile| MOB|          Mobile, AL|Alabama|     46|     51|     41|           35|     9.73|\n",
      "|          0.0|2016-01-03|    1|   3|2016|          Montgomery| MGM|      Montgomery, AL|Alabama|     45|     52|     38|           32|     6.86|\n",
      "|         0.01|2016-01-03|    1|   3|2016|           Anchorage| ANC|       Anchorage, AK| Alaska|     34|     38|     29|           19|      7.8|\n",
      "|         0.09|2016-01-03|    1|   3|2016|             Annette| ANN|         Annette, AK| Alaska|     38|     44|     31|            9|      8.7|\n",
      "|         0.05|2016-01-03|    1|   3|2016|              Bethel| BET|          Bethel, AK| Alaska|     30|     36|     24|            9|    16.46|\n",
      "|         0.15|2016-01-03|    1|   3|2016|             Bettles| BTT|         Bettles, AK| Alaska|     22|     32|      9|            2|      3.1|\n",
      "|          0.6|2016-01-03|    1|   3|2016|            Cold Bay| CDB|        Cold Bay, AK| Alaska|     34|     36|     31|           20|      9.1|\n",
      "|         2.15|2016-01-03|    1|   3|2016|             Cordova| CDV|         Cordova, AK| Alaska|     38|     43|     33|            9|     9.76|\n",
      "|          0.0|2016-01-03|    1|   3|2016|Delta Junction/Ft...| BIG|Delta Junction/Ft...| Alaska|     31|     39|     23|           14|     17.9|\n",
      "|          0.0|2016-01-03|    1|   3|2016|           Fairbanks| FAI|       Fairbanks, AK| Alaska|     14|     30|      4|            2|      2.2|\n",
      "|         0.02|2016-01-03|    1|   3|2016|             Gulkana| GKN|         Gulkana, AK| Alaska|     27|     34|     19|           14|     8.23|\n",
      "|         1.22|2016-01-03|    1|   3|2016|               Homer| HOM|           Homer, AK| Alaska|     39|     42|     35|            9|    11.26|\n",
      "|          0.0|2016-01-03|    1|   3|2016|             Iliamna| ILI|         Iliamna, AK| Alaska|     40|     42|     37|            9|    19.76|\n",
      "|          0.7|2016-01-03|    1|   3|2016|              Juneau| JNU|          Juneau, AK| Alaska|     36|     40|     31|           10|     9.23|\n",
      "|         0.14|2016-01-03|    1|   3|2016|               Kenai| ENA|           Kenai, AK| Alaska|     34|     37|     30|            6|     11.2|\n",
      "|         0.17|2016-01-03|    1|   3|2016|           Ketchikan| KTN|       Ketchikan, AK| Alaska|     37|     41|     33|           15|     6.16|\n",
      "|         0.05|2016-01-03|    1|   3|2016|         King Salmon| AKN|     King Salmon, AK| Alaska|     39|     42|     35|           10|    18.83|\n",
      "|          1.3|2016-01-03|    1|   3|2016|              Kodiak| ADQ|          Kodiak, AK| Alaska|     40|     42|     36|           11|     21.8|\n",
      "+-------------+----------+-----+----+----+--------------------+----+--------------------+-------+-------+-------+-------+-------------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- Precipitation: double (nullable = true)\n",
      " |-- FullDate: date (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- Week: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Code: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- AvgTemp: integer (nullable = true)\n",
      " |-- MaxTemp: integer (nullable = true)\n",
      " |-- MinTemp: integer (nullable = true)\n",
      " |-- WindDirection: integer (nullable = true)\n",
      " |-- WindSpeed: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16743"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the Dataset\n",
    "df = spark.read.csv(\"weather.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Display the contents of the Weather Dataset\n",
    "df.show()\n",
    "\n",
    "# Data types of the Weather Dataset\n",
    "df.printSchema()\n",
    "\n",
    "# Count the no of the rows\n",
    "df.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache Spark Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Specific Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = df.select(\"FullDate\", \"City\", \"AvgTemp\")\n",
    "df_selected.show()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter Rows based on Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.filter((df[\"MaxTemp\"] > 40))\n",
    "df_filtered.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import avg, col\n",
    "\n",
    "window_spec = Window.partitionBy(\"City\").orderBy(\"Week\").rowsBetween(-2, 0)\n",
    "\n",
    "df_3_week_avg_temp = df.select(\n",
    "    col(\"City\"), \n",
    "    col(\"Week\"), \n",
    "    col(\"AvgTemp\"),\n",
    "    avg(\"AvgTemp\").over(window_spec).alias(\"3_Week_Avg_Temperature\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "df_3_week_avg_temp.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import rank, col\n",
    "\n",
    "\n",
    "window_spec = Window.partitionBy(\"City\").orderBy(col(\"AvgTemp\").desc())\n",
    "\n",
    "df_temperature_rank = df.select(\n",
    "    col(\"City\"), \n",
    "    col(\"AvgTemp\"),\n",
    "    rank().over(window_spec).alias(\"Temperature_Rank\")\n",
    ")\n",
    "\n",
    "df_temperature_rank.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binned Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "df_wind_speed_category = df.select(\n",
    "    col(\"WindSpeed\"),\n",
    "    when(col(\"WindSpeed\") < 5, \"Low\")\n",
    "    .when(col(\"WindSpeed\") < 15, \"Medium\")\n",
    "    .otherwise(\"High\")\n",
    "    .alias(\"Wind_Speed_Category\")\n",
    ")\n",
    "\n",
    "df_wind_speed_category.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"Temperature_Category\",\n",
    "    F.when(F.col(\"AvgTemp\").isNull(), \"Unknown\")\n",
    "     .when(F.col(\"AvgTemp\") < 32, \"Cold\")\n",
    "     .when(F.col(\"AvgTemp\") < 70, \"Mild\")\n",
    "     .otherwise(\"Hot\")\n",
    ")\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation between Average Temparature and Wind Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df.stat.corr(\"AvgTemp\", \"WindSpeed\")\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Temperature Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Temperature_Difference\", col(\"MaxTemp\") - col(\"MinTemp\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Union Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "birmingham_df = df.filter(df.City == \"Birmingham\")\n",
    "huntsville_df = df.filter(df.City == \"Huntsville\")\n",
    "union_df = birmingham_df.union(huntsville_df)\n",
    "print(\"Union of Birmingham and Huntsville data:\")\n",
    "union_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Temperature by City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_temp_by_city = df.groupBy(\"City\").agg(round(avg(\"AvgTemp\"), 2).alias(\"Avg_Temperature\"))\n",
    "avg_temp_by_city.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum and Minimum Temperature by City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_min_temp_by_city = df.groupBy(\"City\").agg(\n",
    "    round(avg(\"MaxTemp\"), 2).alias(\"Avg_Max_Temperature\"),\n",
    "    round(avg(\"MinTemp\"), 2).alias(\"Avg_Min_Temperature\")\n",
    ")\n",
    "max_min_temp_by_city.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Wind Speed by City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_wind_speed_by_city = df.groupBy(\"City\").agg(round(avg(\"WindSpeed\"), 2).alias(\"Avg_Wind_Speed\"))\n",
    "avg_wind_speed_by_city.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Precipitation by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_precipitation_by_state = df.groupBy(\"State\").agg(round(avg(\"Precipitation\"), 2).alias(\"Avg_Precipitation\"))\n",
    "avg_precipitation_by_state.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Wind Direction by City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_wind_direction_by_city = df.groupBy(\"City\").agg(round(avg(\"WindDirection\"), 2).alias(\"Avg_Wind_Direction\"))\n",
    "avg_wind_direction_by_city.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Temperature by Month and City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_temp_by_month_city = df.groupBy(\"Month\", \"City\").agg(round(avg(\"AvgTemp\"), 2).alias(\"Avg_Temperature\"))\n",
    "avg_temp_by_month_city.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Precipitation by Year for Each State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_precipitation_by_year_state = df.groupBy(\"Year\", \"State\").agg(round(avg(\"Precipitation\"), 2).alias(\"Total_Precipitation\"))\n",
    "total_precipitation_by_year_state.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing final results to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"results\"\n",
    "df.coalesce(1).write.csv(output_path, header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark Session End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
